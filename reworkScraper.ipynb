{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\2kris\\documents\\code\\pulitzer_web_scraper\\env\\lib\\site-packages (24.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\2kris\\documents\\code\\pulitzer_web_scraper\\env\\lib\\site-packages (75.6.0)\n",
      "Requirement already satisfied: wheel in c:\\users\\2kris\\documents\\code\\pulitzer_web_scraper\\env\\lib\\site-packages (0.45.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Download dependencies\n",
    "\n",
    "%pip install -U pip setuptools wheel\n",
    "%pip install -U spacy \n",
    "%pip install curl-cffi tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "# Download spaCy model. This will return a Language object containing all components and data needed to process text.\n",
    "# Here, I use the default model ('en_core_web_sm') but larger models are available with theoretically more accuracy. \n",
    "# Note, larger models require larger storage which may cause kernel crashes. I recommend running larger models with the python script instead.\n",
    "\n",
    "import spacy\n",
    "spacy.cli.download('en_core_web_sm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from curl_cffi import requests as cureq\n",
    "import json\n",
    "import time\n",
    "import io, requests, pandas as pd\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "import random\n",
    "\n",
    "# Load spaCy NLP model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Set up directory for images\n",
    "current_dir = Path().resolve()\n",
    "output_dir = current_dir / \"images2\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get global JSON. Global JSON is a dictionary in which we can translate the tid values on specific winner webpages to categories and years. \n",
    "# For example, the object with the tid \"274\" is linked to the category, \"Spot News Photography\".\n",
    "def get_global_json(session):\n",
    "    try:\n",
    "        resp = session.get(\n",
    "            \"https://www.pulitzer.org/cache/api/1/global.json\",\n",
    "            impersonate=\"chrome\",\n",
    "            timeout = 10\n",
    "        )\n",
    "        print(f\"Able to get global JSON successfully with response code: {resp.status_code}\")\n",
    "        globalVocab = resp.json()\n",
    "        with open(f'data/globalVocab.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(globalVocab, f, ensure_ascii=False, indent=4)\n",
    "    except:\n",
    "        print(\"Unable to get global JSON. Please try running the code again.\")\n",
    "    return globalVocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate tid to name. Searches global JSON for the tid, in order to find the name associated with it.\n",
    "def get_tid_name(globalVocab, search_tid):\n",
    "    vocabList = globalVocab[\"vocabularies\"]\n",
    "    name = next((ele['name'] for ele in vocabList if ele['tid'] == search_tid), None)\n",
    "    if (name == None):\n",
    "        print(f\"{search_tid} unable to be found\")\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of winner ids (nid) from a category\n",
    "def get_category_nids(session, tid_category, start, end):\n",
    "    try:\n",
    "        resp = session.get(\n",
    "            f\"https://www.pulitzer.org/cache/api/1/winners/cat/{tid_category}/raw.json\",\n",
    "            impersonate=\"chrome\",\n",
    "            timeout = 10\n",
    "        )\n",
    "\n",
    "        winnersList = resp.json()\n",
    "        all_nid_values = [entry[\"nid\"] for entry in winnersList if \"nid\" in entry]\n",
    "        nid_values = all_nid_values[start:end]\n",
    "        print(f\"List of winner ids: {nid_values}\")\n",
    "\n",
    "        # Pulitzer's robots.txt has crawl-delay: 10\n",
    "        time.sleep(10)\n",
    "    except Exception as e:\n",
    "        print(f\"Unable to get nid_values for {tid_category} Error: {e}\")\n",
    "    return nid_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper method for spaCy language processing. \n",
    "# Extracts tokens (recognized words/phrases) from text using spaCy's NLP model. \n",
    "def extract_tokens(text):\n",
    "    if not text:\n",
    "        return []\n",
    "    try:\n",
    "        doc = nlp(text)\n",
    "        return [{\"text\": token.text, \"start_char\": token.start_char, \"end_char\": token.end_char, \"label\": token.label_} for token in doc.ents]\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text with spaCy: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for photographer's or group's name, organization, and locations from the title and caption.\n",
    "\n",
    "# Extract text from parentheses of caption\n",
    "def extract_parentheses_text(caption):\n",
    "    match = re.search(r'\\(([^)]+)\\)', caption)\n",
    "    return match.group(1) if match else \"\"\n",
    "\n",
    "def split_caption(winner, caption):\n",
    "    group = None\n",
    "    photographers = None\n",
    "    organization = None\n",
    "    locations = None\n",
    "\n",
    "    # Caption may have formating that intrudes in spaCy analysis.\n",
    "    # For example, text formatted like AP Photo/Fernando LLano is read as one token and photographer is not able to be identified.\n",
    "    preprocessedCaption = re.sub(r'[/]', ', ', caption)\n",
    "    \n",
    "    # Extract all tokens\n",
    "    winnerTokens = extract_tokens(winner)\n",
    "    captionTokens = extract_tokens(preprocessedCaption)\n",
    "    parenthesesText = extract_parentheses_text(preprocessedCaption)\n",
    "    parenthesesTokens = extract_tokens(parenthesesText)\n",
    "\n",
    "    # Look for names in the title\n",
    "    photographers = [ele['text'] for ele in winnerTokens if ele['label'] == \"PERSON\"]\n",
    "\n",
    "    # If there are no names in winner\n",
    "    if len(photographers) != 1:\n",
    "        # Title must be a group name\n",
    "        group = winner\n",
    "        # Is there \"of\" in the title? Then organization name is after\n",
    "        if \"of\" in winner:\n",
    "            organization = winner.split(\"of\", 1)[1].strip()\n",
    "        else:\n",
    "            # Look in parentheses for organization\n",
    "            organization = next((ele['text'] for ele in parenthesesTokens if ele['label'] == \"ORG\"), None)\n",
    "        # Look for name in caption\n",
    "        photographer = next((ele['text'] for ele in parenthesesTokens if ele['label'] == \"PERSON\"), None)\n",
    "    #If there is one name in winner\n",
    "    else:\n",
    "        photographer = photographers[0]\n",
    "        # Is there \"of\" in the title? Then organization name is after\n",
    "        if \"of\" in winner:\n",
    "            organization = winner.split(\"of\", 1)[1].strip()\n",
    "            # Then photographer name is in caption ()\n",
    "        elif parenthesesText:\n",
    "                organization = next((ele['text'] for ele in parenthesesTokens if ele['label'] == \"ORG\"), None)\n",
    "\n",
    "     # Extract locations from caption tokens\n",
    "    locations = list({ele['text'] for ele in captionTokens if ele['label'] in (\"GPE\", \"LOC\")}) \n",
    "    return group, organization, photographer, locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data from winner's JSON object\n",
    "def get_winner_data(globalVocab, session, nid_list):\n",
    "    for nid in tqdm(nid_list):\n",
    "        try:\n",
    "            resp = session.get(\n",
    "                f\"https://www.pulitzer.org/cache/api/1/node/{nid}/raw.json\",\n",
    "                impersonate=\"chrome\",\n",
    "                timeout = 10\n",
    "            )\n",
    "\n",
    "            resp.raise_for_status()\n",
    "            winnerData = resp.json()\n",
    "\n",
    "            winners  = winnerData[\"title\"]\n",
    "            year = get_tid_name(globalVocab, winnerData[\"field_year\"][\"und\"][0][\"tid\"])\n",
    "            fieldCategory = get_tid_name(globalVocab, winnerData[\"field_category\"][\"und\"][0][\"tid\"])\n",
    "            imageSections = winnerData[\"field_regular_image_slider\"][\"und\"]\n",
    "\n",
    "            imageData = []\n",
    "\n",
    "            for section in imageSections:\n",
    "                item = section[\"item\"]\n",
    "                # Some sections don't have images\n",
    "                try:\n",
    "                    image = item[\"field_slider_image\"][\"und\"][0][\"uri\"][9:]\n",
    "                except:\n",
    "                    continue\n",
    "                # Some images have no captions\n",
    "                try:\n",
    "                    caption = item[\"field_image_caption\"][\"und\"][0][\"safe_value\"]\n",
    "                except:\n",
    "                    caption = \"N/A\"\n",
    "\n",
    "                if image:\n",
    "                    # Look for photographer's or group's name, organization, and locations from the title and caption.\n",
    "                    if caption:\n",
    "                        try:\n",
    "                            group, organization, photographer, locations = split_caption(winners, caption)\n",
    "                        except:\n",
    "                            print(\"Error occured in split caption\")\n",
    "                    \n",
    "                    # Save image\n",
    "                    sanitized_filename = \"\".join(c if c.isalnum() or c in (' ', '.', '_', '-') else '_' for c in image) + \".png\"\n",
    "                    file_path = output_dir / sanitized_filename\n",
    "                    with Image.open(io.BytesIO(requests.get(f\"https://www.pulitzer.org/cms/sites/default/files/styles/image_slider/public/{image}\").content)) as img:\n",
    "                        img.save(file_path, \"PNG\", quality=80)\n",
    "                    \n",
    "                    # Add image data to an array\n",
    "                    imageData.append({\"Image_URL\": image, \n",
    "                                    \"Category\": fieldCategory, \n",
    "                                    \"Year\": year, \n",
    "                                    \"Group\": group or \"\", \n",
    "                                    \"Photographer\": photographer or \"\", \n",
    "                                    \"Organization\": organization or \"\", \n",
    "                                    \"Locations\": locations or \"\", \n",
    "                                    \"Caption\": caption or \"\"})\n",
    "                    \n",
    "            # Write image data to csv file\n",
    "            df = pd.DataFrame(imageData)\n",
    "            df.to_csv('data/winner_data2.csv', mode='a', index=False, encoding='utf-8', header=not Path('data/winner_data.csv').exists())\n",
    "            imageData.clear()\n",
    "\n",
    "            # Pulitzer's robots.txt has crawl-delay: 10\n",
    "            time.sleep(random.uniform(9, 11))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred with getting data for nid: {nid}, {e}. This error is likely due to no images on the page.\")\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function: Start session to get global.JSON, get nid values, and get winner data. \n",
    "def main():\n",
    "\n",
    "    headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\",\n",
    "    \"Accept\": \"application/json\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Referer\": \"https://www.pulitzer.org/\",\n",
    "    }\n",
    "\n",
    "    with cureq.Session() as session:\n",
    "        session.headers.update(headers)\n",
    "\n",
    "        # Get global JSON\n",
    "        globalVocab = get_global_json(session)\n",
    "\n",
    "        # Get a list of winner id values (nid)\n",
    "        feature_photography_nid_list = get_category_nids(session, 217, 0, 30)\n",
    "        print(f\"List of winner ids for Feature Photography: {feature_photography_nid_list}\")\n",
    "        breaking_news_photography_nid_list = get_category_nids(session, 216, 0, 25)\n",
    "        print(f\"List of winner ids for Breaking News Photography: {breaking_news_photography_nid_list}\")\n",
    "        spot_news_photography_nid_list = get_category_nids(session, 274, 0, 15)\n",
    "        print(f\"List of winner ids for Spot News Photography: {spot_news_photography_nid_list}\")\n",
    "\n",
    "        print(\"Getting Feature Photography data\")\n",
    "        get_winner_data(globalVocab, session, feature_photography_nid_list, results)\n",
    "\n",
    "        print(\"Getting Breaking News Photography data\")\n",
    "        get_winner_data(globalVocab, session, breaking_news_photography_nid_list, results)\n",
    "\n",
    "        print(\"Getting Spot News Photography data\")\n",
    "        get_winner_data(globalVocab, session, spot_news_photography_nid_list, results)\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Able to get global JSON successfully with response code: 200\n",
      "List of winner ids: ['22525', '22068', '21685', '21268', '16954', '15993', '15087', '14768', '14443', '7236', '7213', '7183', '7168', '7148', '7126', '7093', '7068', '5667', '7026', '7005', '6985', '6964', '6943', '6921', '6900', '6878', '6857', '6835', '6815', '6794']\n",
      "List of winner ids: ['22524', '22064', '21683', '21689', '21263', '16951', '15991', '15085', '14766', '14435', '14441', '7234', '7212', '7192', '7167', '7147', '7125', '7079', '7067', '7036', '7019', '6997', '6977', '6956', '6935']\n",
      "List of winner ids: ['6889', '6868', '6846', '6826', '6805', '6784', '6764', '6743', '6723', '6702', '6680', '6657', '6635', '6612', '6590']\n",
      "Getting Feature Photography data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [07:34<00:00, 15.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Breaking News Photography data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [06:10<00:00, 14.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Spot News Photography data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [01:03<01:12,  8.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred with getting data for nid: 6784, list indices must be integers or slices, not str. This error is mostly likely because there is no images on the page.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [01:17<00:12,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred with getting data for nid: 6743, list indices must be integers or slices, not str. This error is mostly likely because there is no images on the page.\n",
      "Error occurred with getting data for nid: 6723, list indices must be integers or slices, not str. This error is mostly likely because there is no images on the page.\n",
      "Error occurred with getting data for nid: 6702, list indices must be integers or slices, not str. This error is mostly likely because there is no images on the page.\n",
      "Error occurred with getting data for nid: 6680, list indices must be integers or slices, not str. This error is mostly likely because there is no images on the page.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 13/15 [01:17<00:04,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred with getting data for nid: 6657, list indices must be integers or slices, not str. This error is mostly likely because there is no images on the page.\n",
      "Error occurred with getting data for nid: 6635, list indices must be integers or slices, not str. This error is mostly likely because there is no images on the page.\n",
      "Error occurred with getting data for nid: 6612, list indices must be integers or slices, not str. This error is mostly likely because there is no images on the page.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:30<00:00,  6.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎉 All tasks completed successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run Main\n",
    "main()\n",
    "print(\"🎉 All tasks completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
