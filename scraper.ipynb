{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc79c2bf-2e91-4868-8196-b06223747440",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install curl-cffi spacy tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4c2e7d-2a71-411e-bfd2-857f47da2baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b301240-fd3c-4b90-abbd-21f6dbe18d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import Libraries\n",
    "from curl_cffi import requests as cureq\n",
    "import json\n",
    "import time\n",
    "import io, requests, pandas as pd\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import spacy \n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# Load spaCy NLP model\n",
    "nlp = spacy.load('en_core_web_lg') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade73aa7-cc60-4d58-a619-1ab58140442f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Get global JSON\n",
    "def get_global_json(session):\n",
    "    try:\n",
    "        resp = session.get(\n",
    "            \"https://www.pulitzer.org/cache/api/1/global.json\",\n",
    "            impersonate=\"chrome\"\n",
    "        )\n",
    "        print(resp.status_code)\n",
    "        globalVocab = resp.json()\n",
    "        #create json dump of webpage\n",
    "        with open(f'data/globalVocab.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(globalVocab, f, ensure_ascii=False, indent=4)\n",
    "    except:\n",
    "        print(\"Unable to get global.json\")\n",
    "    return globalVocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fe09d0-0f03-43c5-94e9-9cabc7d79357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Translate tid to name\n",
    "def get_tid_name(globalVocab, search_tid):\n",
    "    vocabList = globalVocab[\"vocabularies\"]\n",
    "    name = next((ele['name'] for ele in vocabList if ele['tid'] == search_tid), None)\n",
    "    if (name == None):\n",
    "        print(f\"{search_tid} unable to be found\")\n",
    "    return name\n",
    "\n",
    "def get_category_nids(session, tid_category, start, end):\n",
    "    try:\n",
    "        resp = session.get(\n",
    "            f\"https://www.pulitzer.org/cache/api/1/winners/cat/{tid_category}/raw.json\",\n",
    "            impersonate=\"chrome\"\n",
    "        )\n",
    "        print(resp.status_code)\n",
    "        winnersList = resp.json()\n",
    "        all_nid_values = [entry[\"nid\"] for entry in winnersList if \"nid\" in entry]\n",
    "        nid_values = all_nid_values[start:end]\n",
    "        print(nid_values)\n",
    "        time.sleep(10)\n",
    "    except Exception as e:\n",
    "        print(f\"Unable to get nid_values for {tid_category} Error: {e}\")\n",
    "    return nid_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06c02c6-7179-4e5c-b7d5-848ae0ae8d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Token Extraction\n",
    "def extract_tokens(text):\n",
    "    # Extracts tokens from text using spaCy's NLP model. \n",
    "    if not text:\n",
    "        return []\n",
    "    try:\n",
    "        doc = nlp(text)\n",
    "        return [{\"text\": token.text, \"start_char\": token.start_char, \"end_char\": token.end_char, \"label\": token.label_} for token in doc.ents]\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text with spaCy: {e}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b035768-b247-47c3-9558-30ffc13a0bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Caption Processing\n",
    "def extract_parentheses_text(caption):\n",
    "    \"\"\" Extracts the text inside parentheses from the caption. \"\"\"\n",
    "    match = re.search(r'\\(([^)]+)\\)', caption)\n",
    "    return match.group(1) if match else \"\"\n",
    "\n",
    "def split_caption(winner, caption):\n",
    "\n",
    "    # looking for these values\n",
    "    group = None\n",
    "    photographers = None\n",
    "    organization = None\n",
    "    locations = None\n",
    "\n",
    "    # caption may have formating that intrudes in spacy analysis \n",
    "    # (text formatted like AP Photo/Fernando LLano is read as one token and photographer is not able to be identified)\n",
    "    preprocessedCaption = re.sub(r'[/]', ', ', caption)\n",
    "    \n",
    "    # Extract all tokens\n",
    "    winnerTokens = extract_tokens(winner)\n",
    "    captionTokens = extract_tokens(preprocessedCaption)\n",
    "    parenthesesText = extract_parentheses_text(preprocessedCaption)\n",
    "    parenthesesTokens = extract_tokens(parenthesesText)\n",
    "\n",
    "    # look for names in winner\n",
    "    photographers = [ele['text'] for ele in winnerTokens if ele['label'] == \"PERSON\"]\n",
    "\n",
    "    #there are no names in winner\n",
    "    if len(photographers) != 1:\n",
    "        # must be a group name\n",
    "        group = winner\n",
    "        # is there \"of\" in the title? then organization name is after\n",
    "        if \"of\" in winner:\n",
    "            organization = winner.split(\"of\", 1)[1].strip()\n",
    "        else:\n",
    "            #look in parentheses for organization\n",
    "            organization = next((ele['text'] for ele in parenthesesTokens if ele['label'] == \"ORG\"), None)\n",
    "        # look for name in caption\n",
    "        photographer = next((ele['text'] for ele in parenthesesTokens if ele['label'] == \"PERSON\"), None)\n",
    "    #there is one name in winner\n",
    "    else:\n",
    "        photographer = photographers[0]\n",
    "        # is there \"of\" in the title? then organization name is after\n",
    "        if \"of\" in winner:\n",
    "            organization = winner.split(\"of\", 1)[1].strip()\n",
    "            # then photographer name is in caption ()\n",
    "        elif parenthesesText:\n",
    "                organization = next((ele['text'] for ele in parenthesesTokens if ele['label'] == \"ORG\"), None)\n",
    "\n",
    "     # Extract locations from caption tokens\n",
    "    locations = list({ele['text'] for ele in captionTokens if ele['label'] in (\"GPE\", \"LOC\")}) \n",
    "    return group, organization, photographer, locations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58937ee0-58e4-4e8c-bda3-b6fb2eb2a4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Get Winner Data\n",
    "def get_winner_data(globalVocab, session, nid_list, results):\n",
    "    for nid in tqdm(nid_list):\n",
    "        try:\n",
    "            resp = session.get(\n",
    "                f\"https://www.pulitzer.org/cache/api/1/node/{nid}/raw.json\",\n",
    "                impersonate=\"chrome\"\n",
    "            )\n",
    "\n",
    "            resp.raise_for_status()\n",
    "            winnerData = resp.json()\n",
    "\n",
    "            winners  = winnerData[\"title\"]\n",
    "            year = get_tid_name(globalVocab, winnerData[\"field_year\"][\"und\"][0][\"tid\"])\n",
    "            fieldCategory = get_tid_name(globalVocab, winnerData[\"field_category\"][\"und\"][0][\"tid\"])\n",
    "            imageSections = winnerData[\"field_regular_image_slider\"][\"und\"]\n",
    "\n",
    "            for section in imageSections:\n",
    "                item = section[\"item\"]\n",
    "                # some sections don't have images\n",
    "                try:\n",
    "                    image = item[\"field_slider_image\"][\"und\"][0][\"uri\"][9:]\n",
    "                except:\n",
    "                    continue\n",
    "                # some images have no captions\n",
    "                try:\n",
    "                    caption = item[\"field_image_caption\"][\"und\"][0][\"safe_value\"]\n",
    "                except:\n",
    "                    caption = \"N/A\"\n",
    "\n",
    "                if image:\n",
    "                    # grab data from caption and compare to winners data\n",
    "                    if caption:\n",
    "                        try:\n",
    "                            group, organization, photographer, locations = split_caption(winners, caption)\n",
    "                        except:\n",
    "                            print(\"Error occured in split caption\")\n",
    "                    results.append({\"Image_URL\": image or \"\", \n",
    "                                    \"Category\": fieldCategory, \n",
    "                                    \"Year\": year, \n",
    "                                    \"Group\": group or \"\", \n",
    "                                    \"Photographer\": photographer or \"\", \n",
    "                                    \"Organization\": organization or \"\", \n",
    "                                    \"Locations\": locations or \"\", \n",
    "                                    \"Caption\": caption or \"\"})\n",
    "            time.sleep(10)\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred with getting data for nid: {nid}, {e}\")\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395b23f5-8f5e-4260-840d-366abe497503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Download Images\n",
    "def get_images(results):\n",
    "    try:\n",
    "        # Get the directory where scrapper.py is located\n",
    "        current_dir = os.getcwd()\n",
    "        #setup directory for images\n",
    "        output_dir = current_dir / \"images\"\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        for result in tqdm(results):\n",
    "            try:\n",
    "                image_url = result[\"Image_URL\"]\n",
    "                sanitized_filename = \"\".join(c if c.isalnum() or c in (' ', '.', '_', '-') else '_' for c in image_url) + \".png\"\n",
    "                image_content = requests.get(f\"https://www.pulitzer.org/cms/sites/default/files/styles/image_slider/public/{image_url}\").content\n",
    "                image_file = io.BytesIO(image_content)\n",
    "                image = Image.open(image_file).convert(\"RGB\")\n",
    "                file_path = output_dir / sanitized_filename\n",
    "                image.save(file_path, \"PNG\", quality=80)\n",
    "            except:\n",
    "                print(f\"This image was not able to be saved {result[\"Image_URL\"]}\")\n",
    "\n",
    "        print(f\"'images' folder created at: {output_dir}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occured: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158828d9-d5ec-453a-9ec5-e3dbf4aebc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Main function\n",
    "def main():\n",
    "#start new session\n",
    "    headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\",\n",
    "    \"Accept\": \"application/json\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Referer\": \"https://www.pulitzer.org/\",\n",
    "    }\n",
    "\n",
    "    with cureq.Session() as session:\n",
    "        session.headers.update(headers)\n",
    "\n",
    "        #Get global vocabulary\n",
    "        globalVocab = get_global_json(session)\n",
    "\n",
    "        #get a list of winner id values (nid)\n",
    "        feature_photography_nid_list = get_category_nids(session, 217, 0, 30)\n",
    "        breaking_news_photography_nid_list = get_category_nids(session, 216, 0, 25)\n",
    "        spot_news_photography_nid_list = get_category_nids(session, 274, 0, 15)\n",
    "\n",
    "\n",
    "        #create csv file with image and caption info\n",
    "        results = []\n",
    "        #get data from each winner's page and apend data to results\n",
    "        print(\"Getting Feature Photography data\")\n",
    "        get_winner_data(globalVocab, session, feature_photography_nid_list, results)\n",
    "        print(\"Getting Breaking News Photography data\")\n",
    "        get_winner_data(globalVocab, session, breaking_news_photography_nid_list, results)\n",
    "        print(\"Getting Spot News Photography data\")\n",
    "        get_winner_data(globalVocab, session, spot_news_photography_nid_list, results)\n",
    "\n",
    "        #update csv file\n",
    "        df = pd.DataFrame(results)\n",
    "        df.to_csv('data/winner_data.csv', index=False, encoding='utf-8')\n",
    "        print(\"data saved to a CSV file\")\n",
    "\n",
    "        #save images\n",
    "        get_images(results)\n",
    "        print(\"Images saved\")\n",
    "\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cde4485-8372-42b3-90f7-6c30a52f8ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Run Main\n",
    "main()\n",
    "print(\"ðŸŽ‰ All tasks completed successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
